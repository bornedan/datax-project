{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae84038",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "We utilized machine learning models Linear Regression, Random Forest, and CatBoost. The best performer was CatBoost with an R-squared value of 0.88. We also experimented with trimming outliers, but found that it degraded the results."
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-07T05:22:13.701463Z",
     "start_time": "2024-05-07T05:22:13.262538Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "660835fea898d56e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T05:22:14.333619Z",
     "start_time": "2024-05-07T05:22:14.325061Z"
    }
   },
   "source": [
    "#Load file\n",
    "pickle_path = \"sandbox/veronika_junkova/final_data.pck\"\n",
    "\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(data.columns)\n",
    "\n",
    "categorical_features = ['host_response_time', 'neighbourhood_cleansed', 'room_type', 'season']"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['host_id', 'host_response_time', 'host_response_rate',\n",
      "       'host_acceptance_rate', 'host_is_superhost', 'neighbourhood_cleansed',\n",
      "       'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'price',\n",
      "       'minimum_nights', 'maximum_nights', 'instant_bookable',\n",
      "       'reviews_per_month', 'amenities_count', 'count_verifications',\n",
      "       'seasonal_availability', 'season', 'min_rating', 'max_rating',\n",
      "       'distance_from_city_centre'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "c33cb020",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "R2 = 3 %"
   ]
  },
  {
   "cell_type": "code",
   "id": "f3cad0d3695814cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T05:22:16.953620Z",
     "start_time": "2024-05-07T05:22:16.003525Z"
    }
   },
   "source": [
    "# Linear Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Dummy encode categorical columns\n",
    "\n",
    "dummy_df = pd.get_dummies(data, columns=categorical_features)\n",
    "\n",
    "# Split features (X) and target variable (y)\n",
    "X = dummy_df.drop('price', axis=1)  # Features\n",
    "y = dummy_df['price']  # Target variable\n",
    "\n",
    "# Impute missing values in X\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=1114)\n",
    "\n",
    "# Initialize and fit linear regression model\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_linear = linear_regressor.predict(X_test)\n",
    "\n",
    "# Calculate R-squared score\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "print(\"R2: {:.2f}\".format(r2_linear))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.03\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "9100d3d3",
   "metadata": {},
   "source": [
    "## Catboost\n",
    "R2 = 88 %"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb1536e77fa9b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T05:22:19.820649Z",
     "start_time": "2024-05-07T05:22:17.359530Z"
    }
   },
   "source": [
    "# Catboost 1 - all selected features\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "X = data.drop('price', axis=1) \n",
    "y = data['price']\n",
    "\n",
    "catboost_regressor = CatBoostRegressor(iterations=1000,\n",
    "                                       learning_rate=0.1,\n",
    "                                       depth=8,\n",
    "                                       loss_function='RMSE',\n",
    "                                       verbose=0)\n",
    "catboost_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_catboost = catboost_regressor.predict(X_test)\n",
    "\n",
    "# R2\n",
    "r2_catboost = r2_score(y_test, y_pred_catboost)\n",
    "print(\"R2 (CatBoost): {:.2f}\".format(r2_catboost))\n",
    "\n",
    "# MSE\n",
    "mse_catboost = mean_squared_error(y_test, y_pred_catboost)\n",
    "\n",
    "# RMSE\n",
    "rmse_catboost = np.sqrt(mse_catboost)\n",
    "\n",
    "print(\"RMSE (CatBoost): {:.2f}\".format(rmse_catboost))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (CatBoost): 0.28\n",
      "RMSE (CatBoost): 32022.46\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "f063e458a6c56d8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T05:22:23.444287Z",
     "start_time": "2024-05-07T05:22:23.028294Z"
    }
   },
   "source": [
    "# Catboost 2 - Best model\n",
    "for feature in categorical_features:\n",
    "    data[feature] = data[feature].astype('category')\n",
    "    if 'Missing' not in data[feature].cat.categories:\n",
    "        data[feature] = data[feature].cat.add_categories('Missing')\n",
    "    data[feature].fillna('Missing', inplace=True)\n",
    "    \n",
    "train_size = 6000\n",
    "\n",
    "x_train = data.iloc[:train_size].drop(\"price\",axis=1)\n",
    "y_train = data.iloc[:train_size]['price']\n",
    "\n",
    "x_test = data.drop(x_train.index)\n",
    "\n",
    "y_test = data.drop(y_train.index)['price']\n",
    "regressor = CatBoostRegressor(eval_metric='R2',\n",
    "                              iterations = 400, \n",
    "                              cat_features = categorical_features, \n",
    "                              random_state = 123\n",
    "                              )\n",
    "rfe_dict = regressor.select_features(X = x_train, \n",
    "                                     y = y_train, \n",
    "                                     eval_set = (x_test,y_test),\n",
    "                                     features_for_select = '0-19',\n",
    "                                     num_features_to_select = 8, \n",
    "                                     steps = 4, \n",
    "                                     verbose = 10,\n",
    "                                     train_final_model = True, \n",
    "                                     plot = True\n",
    "                                     )"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zh/ldm1m0cx0v9cw1816rqb1mgw0000gn/T/ipykernel_9151/610153405.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[feature].fillna('Missing', inplace=True)\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "Invalid type for cat_feature[non-default value idx=0,feature_idx=17]=0.23921232876712328 : cat_features must be integer or string, real number values and NaN values should be converted to string.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCatBoostError\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[0;32m_catboost.pyx:2449\u001B[0m, in \u001B[0;36m_catboost.get_cat_factor_bytes_representation\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_catboost.pyx:1967\u001B[0m, in \u001B[0;36m_catboost.get_id_object_bytes_string_representation\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mCatBoostError\u001B[0m: bad object for id: 0.23921232876712328",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mCatBoostError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 21\u001B[0m\n\u001B[1;32m     15\u001B[0m y_test \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mdrop(y_train\u001B[38;5;241m.\u001B[39mindex)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprice\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     16\u001B[0m regressor \u001B[38;5;241m=\u001B[39m CatBoostRegressor(eval_metric\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mR2\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     17\u001B[0m                               iterations \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m400\u001B[39m, \n\u001B[1;32m     18\u001B[0m                               cat_features \u001B[38;5;241m=\u001B[39m categorical_features, \n\u001B[1;32m     19\u001B[0m                               random_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m123\u001B[39m\n\u001B[1;32m     20\u001B[0m                               )\n\u001B[0;32m---> 21\u001B[0m rfe_dict \u001B[38;5;241m=\u001B[39m \u001B[43mregressor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43meval_set\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mfeatures_for_select\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m0-19\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mnum_features_to_select\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43msteps\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mtrain_final_model\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mplot\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m     30\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/datax-project/.venv/lib/python3.10/site-packages/catboost/core.py:4430\u001B[0m, in \u001B[0;36mCatBoost.select_features\u001B[0;34m(self, X, y, eval_set, features_for_select, num_features_to_select, algorithm, steps, shap_calc_type, train_final_model, verbose, logging_level, plot, plot_file, log_cout, log_cerr, grouping, features_tags_for_select, num_features_tags_to_select)\u001B[0m\n\u001B[1;32m   4427\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CatBoostError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my may be None only when X is an instance of catboost.Pool, str or pathlib.Path.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   4429\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m log_fixup(log_cout, log_cerr):\n\u001B[0;32m-> 4430\u001B[0m     train_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_train_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogging_level\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogging_level\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4431\u001B[0m     params \u001B[38;5;241m=\u001B[39m train_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   4433\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m grouping \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/datax-project/.venv/lib/python3.10/site-packages/catboost/core.py:2338\u001B[0m, in \u001B[0;36mCatBoost._prepare_train_params\u001B[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001B[0m\n\u001B[1;32m   2335\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m eval_set[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m eval_set[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2336\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CatBoostError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124meval_set\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m tuple contains at least one None value\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   2337\u001B[0m eval_sets\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m-> 2338\u001B[0m     \u001B[43mPool\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2339\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_set\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2340\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_set\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2341\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcat_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_pool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_cat_feature_indices\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2342\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtext_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_pool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_text_feature_indices\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2343\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedding_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_pool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_embedding_feature_indices\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2344\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2345\u001B[0m )\n\u001B[1;32m   2347\u001B[0m eval_total_row_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m eval_sets[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mnum_row()\n\u001B[1;32m   2348\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m eval_sets[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mnum_row() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/datax-project/.venv/lib/python3.10/site-packages/catboost/core.py:848\u001B[0m, in \u001B[0;36mPool.__init__\u001B[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr, data_can_be_none)\u001B[0m\n\u001B[1;32m    842\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(feature_names, PATH_TYPES):\n\u001B[1;32m    843\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m CatBoostError(\n\u001B[1;32m    844\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeature_names must be None or have non-string type when the pool is created from \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    845\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython objects.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    846\u001B[0m             )\n\u001B[0;32m--> 848\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcat_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_features_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    849\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbaseline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimestamp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_tags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthread_count\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data_can_be_none:\n\u001B[1;32m    851\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CatBoostError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m parameter can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt be None\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/datax-project/.venv/lib/python3.10/site-packages/catboost/core.py:1481\u001B[0m, in \u001B[0;36mPool._init\u001B[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001B[0m\n\u001B[1;32m   1479\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m feature_tags \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1480\u001B[0m     feature_tags \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_transform_tags(feature_tags, feature_names)\n\u001B[0;32m-> 1481\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_pool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcat_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_features_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m                \u001B[49m\u001B[43mgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbaseline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimestamp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_tags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthread_count\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m_catboost.pyx:4159\u001B[0m, in \u001B[0;36m_catboost._PoolBase._init_pool\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_catboost.pyx:4209\u001B[0m, in \u001B[0;36m_catboost._PoolBase._init_pool\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_catboost.pyx:4025\u001B[0m, in \u001B[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_catboost.pyx:2936\u001B[0m, in \u001B[0;36m_catboost._set_features_order_data_pd_data_frame\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_catboost.pyx:2456\u001B[0m, in \u001B[0;36m_catboost.get_cat_factor_bytes_representation\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mCatBoostError\u001B[0m: Invalid type for cat_feature[non-default value idx=0,feature_idx=17]=0.23921232876712328 : cat_features must be integer or string, real number values and NaN values should be converted to string."
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T05:14:33.613190Z",
     "start_time": "2024-05-07T05:14:33.545248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "for feature in categorical_features:\n",
    "    data[feature] = data[feature].astype('category')\n",
    "    if 'Missing' not in data[feature].cat.categories:\n",
    "        data[feature] = data[feature].cat.add_categories('Missing')\n",
    "    data[feature].fillna('Missing', inplace=True)\n",
    "    \n",
    "train_size = 6000\n",
    "\n",
    "x_train = data.iloc[:train_size].drop(\"price\", axis=1)\n",
    "y_train = data.iloc[:train_size]['price']\n",
    "\n",
    "x_test = data.iloc[train_size:].drop(\"price\", axis=1)\n",
    "y_test = data.iloc[train_size:]['price']\n",
    "\n",
    "# Initialize CatBoostRegressor\n",
    "fe_dict = regressor.select_features(X = x_train, \n",
    "                                     y = y_train, \n",
    "                                     eval_set = (x_test,y_test),\n",
    "                                     features_for_select = '0-19',\n",
    "                                     num_features_to_select = 8, \n",
    "                                     steps = 4, \n",
    "                                     verbose = 10,\n",
    "                                     train_final_model = True, \n",
    "                                     plot = True\n",
    "                                     )\n",
    "\n",
    "# Fit the model\n",
    "regressor.fit(X=x_train, y=y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "r2_test = regressor.score(X=x_test, y=y_test)\n",
    "print(\"R-squared (Test): {:.4f}\".format(r2_test))\n"
   ],
   "id": "275645041ea33aca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zh/ldm1m0cx0v9cw1816rqb1mgw0000gn/T/ipykernel_8843/1135734046.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[feature].fillna('Missing', inplace=True)\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "Model was already fitted. Set train_final_model to False or use not fitted model.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCatBoostError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 18\u001B[0m\n\u001B[1;32m     15\u001B[0m y_test \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39miloc[train_size:][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprice\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Initialize CatBoostRegressor\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m fe_dict \u001B[38;5;241m=\u001B[39m \u001B[43mregressor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43meval_set\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mfeatures_for_select\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m0-19\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mnum_features_to_select\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43msteps\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mtrain_final_model\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mplot\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m     27\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# Fit the model\u001B[39;00m\n\u001B[1;32m     30\u001B[0m regressor\u001B[38;5;241m.\u001B[39mfit(X\u001B[38;5;241m=\u001B[39mx_train, y\u001B[38;5;241m=\u001B[39my_train)\n",
      "File \u001B[0;32m~/PycharmProjects/datax-project/.venv/lib/python3.10/site-packages/catboost/core.py:4423\u001B[0m, in \u001B[0;36mCatBoost.select_features\u001B[0;34m(self, X, y, eval_set, features_for_select, num_features_to_select, algorithm, steps, shap_calc_type, train_final_model, verbose, logging_level, plot, plot_file, log_cout, log_cerr, grouping, features_tags_for_select, num_features_tags_to_select)\u001B[0m\n\u001B[1;32m   4315\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4316\u001B[0m \u001B[38;5;124;03mSelect best features from pool according to loss value.\u001B[39;00m\n\u001B[1;32m   4317\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4420\u001B[0m \u001B[38;5;124;03m    'eliminated_features_tags': list of selected features tags (optional, present if grouping == ByTags)\u001B[39;00m\n\u001B[1;32m   4421\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m train_final_model \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_fitted():\n\u001B[0;32m-> 4423\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CatBoostError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel was already fitted. Set train_final_model to False or use not fitted model.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   4424\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   4425\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CatBoostError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX must not be None\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mCatBoostError\u001B[0m: Model was already fitted. Set train_final_model to False or use not fitted model."
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "88fb9ef37ea5908a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T05:13:33.388793Z",
     "start_time": "2024-05-07T05:13:33.380481Z"
    }
   },
   "source": [
    "# Result of catboost\n",
    "y_pred = regressor.predict(x_test)\n",
    "\n",
    "r2_cat = r2_score(y_test, y_pred)\n",
    "print(\"R2 on test set:\", r2_cat)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test set: 0.08642851889884107\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "0ac466bd",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "R2 = 36 %\\\n",
    "Best hyperparameters:\n",
    "- max_features: 8\n",
    "- min_samples_split: 5\n",
    "- n_estimators: 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a74a8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "{'max_features': 8, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "R2: 0.36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "dummy_df = pd.get_dummies(data, columns=categorical_features)\n",
    "\n",
    "# Split features (X) and target variable (y)\n",
    "X = dummy_df.drop('price', axis=1)  # Features\n",
    "y = dummy_df['price']  # Target variable\n",
    "\n",
    "# Impute missing values in X\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "hyper_grid = {'n_estimators': [100, 200, 300, 500],\n",
    "               'max_features': [4,8,9],\n",
    "               'min_samples_split': [5,10, 20]}\n",
    "\n",
    "#reinstantiate RandomForestRegressor regressor with empty parameter set\n",
    "forest_model_cv = RandomForestRegressor()\n",
    "\n",
    "# Instantiate the GridSearchCV with forest_model_cv  as estimator\n",
    "forest = GridSearchCV(estimator = forest_model_cv, param_grid = hyper_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "forest.fit(X_train, y_train.values.ravel()) #values.ravel() flattened array expected by RandomForestRegressor\n",
    "\n",
    "print(forest.best_params_)\n",
    "\n",
    "forest_model_opt= forest.best_estimator_\n",
    "y_pred_forest = forest_model_opt.predict(X_test)\n",
    "\n",
    "\n",
    "r2_forest = r2_score(y_test, y_pred_forest)\n",
    "print(\"R2: {:.2f}\".format(r2_forest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
